% !TEX TS-program = pdflatex
\documentclass[12pt]{article}
\usepackage{amsmath, amssymb, bm, geometry, graphicx}
\usepackage{hyperref}
\geometry{margin=1in}
\title{\textbf{\huge Programming in Economics \& Finance II, Final Project}}
\author{Niccol\`o Lecce, Marco Gasparetti, Alessandro Dodon}
\date{}

\begin{document}

\maketitle

\textbf{Python Package for Efficient VaR Estimation}

This document presents the theoretical foundations, implementation overview, and risk estimation models behind our Python package for Value-at-Risk (VaR) and Expected Shortfall (ES). All code, deployment steps, and documentation are published on GitHub.


\textbf{Project Plan}

xxx

% [Fill in the details of your plan here.]

\textbf{Project Diary}

xxx

% [Describe your steps, tool choices, and implementation chronology here.]

\textbf{Theoretical Foundation}

\vspace{1em}
\underline{\text{Basic VaR Models}}

\vspace{0.6em}

We implement two main approaches for Value-at-Risk (VaR) estimation. The first is non-parametric historical VaR, which computes the empirical quantile of past returns at a given confidence level $\alpha$. The second is parametric VaR, which assumes a specific distribution for returns. We support the normal, Student-$t$, and generalized error distribution (GED), and estimate the critical value $z_\alpha$ accordingly.

To complement VaR, we compute expected shortfall (ES), defined as the average loss beyond the VaR threshold. For the historical method:
\[
\text{ES}_{\mathrm{hist}} = -\mathbb{E}[r_t \mid r_t < -\text{VaR}_\alpha].
\]

For the parametric case, we use analytical formulas for the normal and Student-$t$ distributions:

Normal:
\[
\text{ES}_{\mathrm{normal}} = \sigma \cdot \frac{\phi(z_\alpha)}{1 - \alpha},
\]

Student-$t$:
\[
\text{ES}_{t,\alpha} = \sigma \cdot \frac{f_{t_\nu}(t_\alpha)}{1 - \alpha} \cdot \frac{\nu + t_\alpha^2}{\nu - 1},
\]

where $\phi(\cdot)$ and $f_{t_\nu}(\cdot)$ denote the corresponding density functions. ES values are scaled by $\sqrt{h}$ for a holding period of $h$ days.



\vspace{1em}
\underline{\text{Volatility Models}}

\vspace{0.6em}

We have implemented the four most popular univariate volatility models.

The GARCH(1,1) model is specified as:
\[
  \sigma_t^2 = \omega + \alpha r_{t-1}^2 + \beta \sigma_{t-1}^2, \qquad r_t = \sigma_t z_t,
\]
where $z_t$ are i.i.d.\ standardized shocks. Value-at-Risk is then computed as:
\[
  \text{VaR}_{t,\alpha} = -\hat{\sigma}_t \; z_\alpha.
\]


Expected Shortfall (ES) here becomes:
\[
  \text{ES}_{t,\alpha} = -\hat{\sigma}_t \,\mathbb{E}[z_t \mid z_t < z_\alpha].
\]

Future volatility can be forecasted analytically using GARCH(1,1). 

The $\tau$-step ahead forecast and cumulative $T$-step forecast are:
\begin{align*}
  \mathbb{E}[\sigma_{t+\tau}^2] &= \mathrm{VL} + (\alpha+\beta)^\tau(\sigma_t^2 - \mathrm{VL}),  \\  
  \mathbb{E}[\sigma_{t,T}^2] &= \mathrm{VL}\left(T-1 - \frac{(\alpha+\beta)(1-(\alpha+\beta)^{T-1})}{1-(\alpha+\beta)}\right)
    + \sigma_t^2\,\frac{1-(\alpha+\beta)^T}{1-(\alpha+\beta)},
\end{align*}
leading to multi-period VaR:
\[
  \text{VaR}_{t,T} = -\,z_\alpha \,\sqrt{\mathbb{E}[\sigma_{t,T}^2]}.
\]

In our implementation, we also support advanced GARCH-type models including EGARCH, GJR-GARCH, and APARCH. Additionally, we allow maximum likelihood estimation under various distributional assumptions such as Normal, Student-$t$, GED, and Skewed-$t$.

We also include the basic ARCH($p$) model:
\[
  \sigma_t^2 = \omega + \sum_{i=1}^p \alpha_i \varepsilon_{t-i}^2.
\]

For simpler estimators, we implement a Moving Average (MA) volatility model:
\[
  \sigma_t^2 = \frac{1}{n} \sum_{i=1}^n r_{t-i}^2.
\]

And an Exponentially Weighted Moving Average (EWMA) model:
\[
  \sigma_t^2 = \lambda \sigma_{t-1}^2 + (1 - \lambda) r_{t-1}^2,
\]
where $\lambda \in (0,1)$ controls the decay rate of past observations.
All our volatility models use a semi-empirical approach for the VaR computation, first calculating the empirical distribution of innovations with their respective volatility estimate and then using the required percentile of those innovations as z.

\vspace{1em}
\underline{\text{Time-Varying Correlation Models}}
\vspace{1em}
\underline{\text{Correlation-Based VaR Implementation}}

\vspace{0.6em}

We implemented two correlation-based portfolio Value-at-Risk (VaR) models using time-varying covariance matrices estimated from historical returns. Both models assume normally distributed asset returns and rely on daily monetary position data to compute risk metrics under a buy-and-hold strategy.

\textit{Moving Average (MA) Covariance:}  
We use a rolling window approach to compute the empirical covariance matrix of returns over the past $n$ days. At each time $t$, the portfolio variance is calculated as $x_t^\top \Sigma_t x_t$, where $x_t$ represents the vector of monetary positions and $\Sigma_t$ is the sample covariance. Volatility is scaled by total portfolio value, and VaR is computed analytically using the Gaussian quantile $z_\alpha$.

\textit{Exponentially Weighted Moving Average (EWMA):}  
Following the RiskMetrics approach, we recursively update the covariance matrix using the formula:
\[
\Sigma_t = \lambda \Sigma_{t-1} + (1 - \lambda) r_{t-1} r_{t-1}^\top,
\]
where $\lambda$ is the decay factor (typically 0.94). This method gives more weight to recent returns and captures time-varying volatility and correlation. The final VaR expression is identical, but based on the EWMA covariance matrix at each point in time.

Both implementations also compute monetary VaR and identify violations when actual losses exceed the estimated VaR. These functions ensure a strictly positive portfolio value and are robust to asset-level fluctuations.

\vspace{0.6em}

We implement the two simplest time-varying correlation models: moving average (MA) and exponentially weighted moving average (EWMA). These serve as natural multivariate extensions of the corresponding univariate volatility models.

Portfolio VaR is computed using the parametric normal assumption. Given the monetary position vector $x_t$ and the time-varying covariance matrix $\Sigma_t$ estimated by the model, VaR is calculated as:
\[
\text{VaR}_t = z_\alpha \cdot \sqrt{x_t^\top \Sigma_t x_t}.
\]

More advanced models like DCC-GARCH or VEC(1,1) are not easily supported in Python and are therefore not included.

Expected Shortfall in this setting is computed using the analytical formula under the normal distribution assumption.


\vspace{1em}
\underline{\text{Portfolio Metrics}}

\vspace{0.6em}

We compute several portfolio-level Value-at-Risk (VaR) measures using monetary positions $x_t = (x_{1,t}, \dots, x_{N,t})^\top$, the return covariance matrix $\Sigma$, and a time horizon of $h$ days. Note that there is no distinct parametric VaR function for a normally distributed portfolio—standard parametric normal VaR applies directly, where total portfolio risk is computed using the aggregate monetary exposure.

The quantile $z_\alpha$ corresponds to the desired confidence level and is always derived from the standard normal distribution, as the underlying assumption is that asset returns (or their innovations) are normally distributed.

The asset-normal parametric portfolio VaR is defined as:
\[
  \text{VaR}_t = z_\alpha \cdot \sqrt{x_t^\top \Sigma x_t} \cdot \sqrt{h}.
\]

Assuming all asset returns are perfectly correlated ($\rho = 1$) and there are no short positions, the undiversified portfolio VaR is simply the sum of the individual asset VaRs:
\[
  \text{UVaR}_t = \sum_{i=1}^N \text{VaR}_{i,t}.
\]

The marginal VaR, representing the sensitivity of portfolio VaR to a small change in position $x_{i,t}$, is given by:
\[
  \Delta \text{VaR}_{i,t} = \text{VaR}_t \cdot \frac{(\Sigma x_t)_i}{x_t^\top \Sigma x_t}.
\]
It measures the change in total VaR from adding one extra unit of asset $i$.

The component VaR is:
\[
  \text{CVaR}_{i,t} = x_{i,t} \cdot \Delta \text{VaR}_{i,t},
\]
which captures the absolute contribution of asset $i$ to total portfolio VaR.

The relative component VaR is:
\[
  \text{RCVaR}_{i,t} = \frac{\text{CVaR}_{i,t}}{\text{VaR}_t},
\]
interpreted as the percentage share of total VaR attributable to asset $i$.

For a vector $a$ representing changes in the portfolio allocation, the incremental VaR is:
\[
  \text{IVaR}_t = \Delta \text{VaR}_t^\top \cdot a,
\]
which estimates the change in total VaR resulting from shifting the portfolio by $a$.

Each of these portfolio-level VaR metrics can be complemented with a corresponding Expected Shortfall (ES), computed under the normality assumption.


\vspace{1em}
\underline{\text{Extreme Value Theory}}

\vspace{0.6em}

We implement Extreme Value Theory (EVT) using the Peaks Over Threshold (POT) approach to estimate risk in the far tail of the loss distribution. Once a high threshold $u$ is selected (e.g., the 99th percentile of losses), we fit a Generalized Pareto Distribution (GPD) to the excesses above $u$.

VaR and ES are then derived analytically from the fitted GPD parameters. This allows for more accurate estimation of rare, extreme losses compared to historical simulation. The formulas used are:

\[
\widehat{\text{VaR}}_\alpha = u + \frac{\hat{\beta}}{\hat{\xi}} \left[ \left( \frac{n}{n_u}(1 - \alpha) \right)^{-\hat{\xi}} - 1 \right],
\]
\[
\widehat{\text{ES}}_\alpha = \frac{\widehat{\text{VaR}}_\alpha + \hat{\beta} - \hat{\xi} u}{1 - \hat{\xi}},
\]

where $\hat{\xi}$ and $\hat{\beta}$ are the estimated shape and scale parameters, $n$ is the sample size, and $n_u$ is the number of exceedances.

We also allow computing the probability of exceeding a specified extreme loss. EVT complements our other risk models by focusing explicitly on the behavior of the tail.

For EVT, basic VaR methods and volatility models, as well as their corresponding ES measures, it is always possible to use wealth as additional input to receive a monetary measure and not in percentage.

\vspace{1em}
\underline{\text{Factor Models}}

\vspace{0.6em}

We implement two standard linear factor models to estimate portfolio Value-at-Risk (VaR) and Expected Shortfall (ES). These models use asset betas with respect to systematic risk factors, allowing us to infer portfolio-level risk from exposures to common sources of variation.

\textit{Sharpe Single-Factor Model:}  
We assume that each asset’s return $r_i$ follows the linear factor structure:
\[
r_i = \alpha_i + \beta_i r_m + \varepsilon_i,
\]
where $r_m$ is the return on the market portfolio, $\beta_i$ is the asset's sensitivity to the market factor, and $\varepsilon_i$ is a zero-mean idiosyncratic shock uncorrelated with $r_m$ and other residuals. The market return $r_m$ has variance $\sigma_m^2$, and $\mathrm{Var}(\varepsilon_i) = \sigma_{\varepsilon_i}^2$.

Let $w = (w_1, \dots, w_N)^\top$ be the vector of monetary portfolio weights. Then the total portfolio variance becomes:
\[
\sigma_p^2 = \left(\sum_{i=1}^N w_i \beta_i\right)^2 \sigma_m^2 + \sum_{i=1}^N w_i^2 \sigma_{\varepsilon_i}^2.
\]

VaR and ES are computed under the normality assumption:
\[
\text{VaR}_{t,\alpha} = z_\alpha \cdot \sigma_p, \qquad
\text{ES}_{t,\alpha} = \sigma_p \cdot \frac{\phi(z_\alpha)}{1 - \alpha},
\]
where $\phi(z)$ is the standard normal PDF.

\textit{Fama-French 3-Factor Model:}  
We extend the previous model by considering three risk factors: market excess return (Mkt-RF), size (SMB), and value (HML). Each asset’s excess return is modeled as:
\[
r_i - r_f = \alpha_i + \beta_{i,1} \cdot \text{Mkt-RF} + \beta_{i,2} \cdot \text{SMB} + \beta_{i,3} \cdot \text{HML} + \varepsilon_i,
\]
where $r_f$ is the risk-free rate, and $\varepsilon_i$ is the idiosyncratic error. We estimate factor loadings $\beta_{i,k}$ through OLS regression.

Let $\mathbf{B}$ be the $N \times 3$ matrix of estimated factor loadings, $\Sigma_f$ the $3 \times 3$ sample covariance matrix of the factors, and $\Sigma_\varepsilon$ the diagonal matrix of residual variances $\sigma_{\varepsilon_i}^2$. The total portfolio variance is:
\[
\sigma_p^2 = w^\top (\mathbf{B} \Sigma_f \mathbf{B}^\top + \Sigma_\varepsilon) w.
\]

Once the portfolio variance is known, we compute:
\[
\text{VaR}_{t,\alpha} = z_\alpha \cdot \sigma_p, \qquad
\text{ES}_{t,\alpha} = \sigma_p \cdot \frac{\phi(z_\alpha)}{1 - \alpha}.
\]

The Fama-French model implementation includes automatic download and alignment of factor data from Kenneth French’s online library. The routine supports time-series generation of both VaR and ES and flags violations. Negative exposures and short positions are highlighted for interpretability and consistency with the risk management framework.

\vspace{0.6em}

\vspace{1em}
\underline{\text{Simulation Methods}}

\vspace{0.6em}
\underline{\text{Parametric Monte Carlo (Equities \& Options)}}

\vspace{0.6em}
We implement a one-day parametric Monte Carlo simulation approach to estimate VaR and ES. Under the assumption of multivariate normality, we simulate future returns as:
\[
\boldsymbol{\mu} = \mathbb{E}[r_t], \quad \Sigma = \text{Cov}(r_t), \quad L = \text{Cholesky}(\Sigma),
\]
\[
\mathbf{r}^{(i)} = \boldsymbol{\mu} + L \mathbf{z}^{(i)}, \quad \mathbf{z}^{(i)} \sim \mathcal{N}(\mathbf{0}, I),
\]
\[
\mathbf{S}^{(i)} = \mathbf{S}_0 \circ (1 + \mathbf{r}^{(i)}),
\]
where $\circ$ denotes element-wise multiplication.

The simulated P\&L of the portfolio is calculated as:
\[
\Delta P^{(i)} = \mathbf{w}^\top(\mathbf{S}^{(i)} - \mathbf{S}_0) + \sum_{j=1}^{N_{\mathrm{opt}}} q_j \left(C(S_j^{(i)}, \tau_j') - C_{j,0}\right),
\]
where $q_j$ is the number of contracts for option $j$, $C(\cdot)$ is the Black-Scholes option price, and $\tau_j' = \max(T_j - \frac{1}{252}, 0)$ is the adjusted time to maturity.

From the empirical distribution of $\{\Delta P^{(i)}\}_{i=1}^N$, we compute:
\[
\text{VaR}_\alpha = -\text{Quantile}_\alpha(\Delta P), \qquad
\text{ES}_\alpha = -\mathbb{E}[\Delta P \mid \Delta P \le -\text{VaR}_\alpha].
\]

\vspace{1em}
\underline{\text{Multiday Monte Carlo (Equity-only)}}

\vspace{0.6em}
To simulate risk over multiple days ($h$-day horizon) for pure equity portfolios, we model prices as following a geometric Brownian motion:
\[
S_{t+1}^{(i)} = S_t^{(i)} \cdot \exp\left(\mu - \frac{1}{2} \sigma^2 + L z_t^{(i)}\right), \quad z_t^{(i)} \sim \mathcal{N}(0, I),
\]
for $t = 0, \dots, h-1$, where $L$ is the Cholesky factor of the covariance matrix.

The final P\&L is:
\[
\Delta P^{(i)} = \sum_{k=1}^N w_k (S_{h,k}^{(i)} - S_{0,k}).
\]

The VaR and ES are computed from the empirical distribution of simulated $\Delta P^{(i)}$.

\vspace{1em}
\underline{\text{Historical \& Bootstrapped Simulation}}

\vspace{0.6em}
We simulate alternative return paths by re-applying historical return vectors to the current portfolio composition. For each scenario $i$, we define:
\[
\mathbf{S}^{(i)} = \mathbf{S}_0 \circ (1 + r_{\pi(i)}),
\]
where $r_{\pi(i)}$ is the $i$-th sampled return vector from the historical dataset, and $\pi(i)$ is either a fixed ordering (historical simulation) or a random draw (bootstrap simulation).

The corresponding P\&L is:
\[
\Delta P^{(i)} = \mathbf{w}^\top (\mathbf{S}^{(i)} - \mathbf{S}_0).
\]

Risk measures are then computed as:
\[
\text{VaR}_\alpha = -\text{Quantile}_\alpha(\Delta P), \qquad
\text{ES}_\alpha = -\mathbb{E}[\Delta P \mid \Delta P \le -\text{VaR}_\alpha].
\]

This approach is fully non-parametric and accounts for fat tails and nonlinear dependence in historical returns. When bootstrap is enabled, multiple resamples ensure robustness to limited data windows.

\vspace{0.6em}

\underline{\text{Backtesting}}

\vspace{0.6em}

Backtesting assesses whether the observed losses are consistent with the Value-at-Risk (VaR) predictions by checking the frequency and structure of violations (exceptions). The objective is to test whether the model is correctly calibrated.

We implement three standard tests.

The \textit{Kupiec test} (unconditional coverage) evaluates if the number of observed exceptions $N$ over $T$ days matches the expected number under the model. If $p$ is the failure probability, then under the null $N$ follows a binomial distribution. The likelihood ratio test statistic is:
\[
\text{LR}_{\text{uc}} = -2 \left\{ \ln\left[(1 - p)^{T - N} p^N \right] - \ln\left[(1 - \hat{p})^{T - N} \hat{p}^N \right] \right\}, \quad \hat{p} = \frac{N}{T}, \quad \text{LR}_{\text{uc}} \sim \chi^2_1.
\]

The \textit{Christoffersen test} (conditional coverage) tests the independence of exceptions by modeling their dynamics as a first-order Markov chain. It compares the likelihoods of transition counts under the null (independence) and alternative. The statistic is:
\[
\text{LR}_{\text{c}} = -2 (\ln L_0 - \ln L_1), \quad \text{LR}_{\text{c}} \sim \chi^2_1,
\]
where $L_0$ is the likelihood under independence and $L_1$ under the alternative.

The \textit{joint test} combines both:
\[
\text{LR} = \text{LR}_{\text{uc}} + \text{LR}_{\text{c}} \sim \chi^2_2.
\]

Rejecting the null in any of the tests suggests that the VaR model is either miscalibrated (too many or too few violations) or fails to capture time dependence in risk (e.g., volatility clustering).



\textbf{Results and Applications}

xxx
% [Add your outputs, charts, application examples, interpretations.]

\textbf{Lessons Learned}

xxx
% [Write your reflections here.]

\textbf{AI Acknowledgement}

xxx

\textbf{Link to GitHub Repository}

xxx

\end{document}

